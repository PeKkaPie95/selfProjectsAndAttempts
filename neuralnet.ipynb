{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCJ9PIxZF++qDDBqdQ7nEJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeKkaPie95/selfProjectsAndAttempts/blob/main/neuralnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baJ3HAO8M5SB"
      },
      "outputs": [],
      "source": [
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.io import wavfile as wav\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
        "labels = list(df['class'].unique())"
      ],
      "metadata": {
        "id": "0pQu7khQx4qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = dict()\n",
        "for i in range(len(labels)):\n",
        "    tmp = df[df['class'] == labels[i]][:1].reset_index()\n",
        "    path = 'UrbanSound8K/audio/fold{}/{}'.format(tmp['fold'][0], tmp['slice_file_name'][0])\n",
        "    files[labels[i]] = path"
      ],
      "metadata": {
        "id": "8zDZz7eePiKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(15,15))\n",
        "experiment.log_image('class_examples.png')\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "for i, label in enumerate(labels):\n",
        "    fn = files[label]\n",
        "    fig.add_subplot(5, 2, i+1)\n",
        "    plt.title(label)\n",
        "    data, sample_rate = librosa.load(fn)\n",
        "    librosa.display.waveplot(data, sr= sample_rate)\n",
        "plt.savefig('class_examples.png')"
      ],
      "metadata": {
        "id": "B4cKNex5Pw4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment.log_image('class_examples.png')"
      ],
      "metadata": {
        "id": "qjxbMTZ3P3pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label in labels:\n",
        "    fn = files[label]\n",
        "    experiment.log_audio(fn, metadata = {'name': label})"
      ],
      "metadata": {
        "id": "ElvOwJieQJFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 'UrbanSound8K/audio/fold1/191431-9-0-66.wav'\n",
        "librosa_audio, librosa_sample_rate = librosa.load(fn)\n",
        "scipy_sample_rate, scipy_audio = wav.read(fn)\n",
        "print(\"Original sample rate: {}\".format(scipy_sample_rate))\n",
        "print(\"Librosa sample rate: {}\".format(librosa_sample_rate))"
      ],
      "metadata": {
        "id": "l7RoXJQeQNpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original audio file min~max range: {} to {}'.format(np.min(scipy_audio), np.max(scipy_audio)))print('Librosa audio file min~max range: {0:.2f} to {0:.2f}'.format(np.min(librosa_audio), np.max(librosa_audio)))"
      ],
      "metadata": {
        "id": "xUPWMLp8QQIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(scipy_audio)\n",
        "plt.savefig('original_audio.png')\n",
        "experiment.log_image('original_audio.png')"
      ],
      "metadata": {
        "id": "FaUuRYJ4QfYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(librosa_audio)\n",
        "plt.savefig('librosa_audio.png')\n",
        "experiment.log_image('librosa_audio.png')"
      ],
      "metadata": {
        "id": "ZdqC9fj6Sabz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfccs = librosa.feature.mfcc(y=librosa_audio, sr=librosa_sample_rate, n_mfcc = 40)"
      ],
      "metadata": {
        "id": "P7nmjKYrSe-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mfccs.shape)"
      ],
      "metadata": {
        "id": "bdX9WqNsSihk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "librosa.display.specshow(mfccs, sr=librosa_sample_rate, x_axis='time')\n",
        "plt.savefig('MFCCs.png')\n",
        "experiment.log_image('MFCCs.png')"
      ],
      "metadata": {
        "id": "oQAhcaKiSlm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(file_name):audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
        "\n",
        "    return mfccs_processed"
      ],
      "metadata": {
        "id": "91V7tbiDSpCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = []\n",
        "for index, row in metadata.iterrows():file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
        "\n",
        "    class_label = row[\"class\"]\n",
        "    data = extract_features(file_name)\n",
        "\n",
        "    features.append([data, class_label])\n",
        "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])"
      ],
      "metadata": {
        "id": "9SuUtubVSthZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuresdf.head()"
      ],
      "metadata": {
        "id": "9KGlzasaS1CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuresdf.iloc[0]['feature']"
      ],
      "metadata": {
        "id": "YC0d9BA1S5j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "X = np.array(featuresdf.feature.tolist())\n",
        "y = np.array(featuresdf.class_label.tolist())\n",
        "\n",
        "le = LabelEncoder()\n",
        "yy = to_categorical(le.fit_transform(y))"
      ],
      "metadata": {
        "id": "yVACn8hqS958"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 127)"
      ],
      "metadata": {
        "id": "nQ5F12-lTFYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = yy.shape[1]\n",
        "filter_size = 2def build_model_graph(input_shape=(40,)):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_labels))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "    return modelmodel = build_model_graph()"
      ],
      "metadata": {
        "id": "PYWR8ifMTJha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "accuracy = 100*score[1]\n"
      ],
      "metadata": {
        "id": "gk9iURxoTOI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
      ],
      "metadata": {
        "id": "Cz6Rek17TVTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime\n",
        "num_epochs = 100\n",
        "num_batch_size = 32\n",
        "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)"
      ],
      "metadata": {
        "id": "srQLLBcRTaPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))"
      ],
      "metadata": {
        "id": "f_aMkF7cTdxR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}